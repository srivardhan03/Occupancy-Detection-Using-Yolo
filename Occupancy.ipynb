{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "je2tvd8Gu7YZ",
    "outputId": "9e984fb2-ddaa-4700-891a-720ee3d660c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  2.3 ; cuda:  2.3.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6qsQaKLF0et7",
    "outputId": "530d3d1b-522f-43e2-fa99-df20a13eee27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ezhil/Downloads\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2QOd7O0Xw3G"
   },
   "source": [
    "**INSTALLING YOLOv5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xV9ROeyqXwPN"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "\n",
    "%cd {HOME}/yolov5\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ern2bvVG04GW"
   },
   "source": [
    "**INSTALLING YOLOv8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8w4nepQU00rY",
    "outputId": "05be9a44-4eff-4072-80d9-a67d80efafcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.20 ðŸš€ Python-3.11.5 torch-2.3.0 CPU (Apple M2)\n",
      "Setup complete âœ… (8 CPUs, 8.0 GB RAM, 304.0/460.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIx3WRFMcdLz"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "**INSTALLING DETECTRON2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.3.0)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.18.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (1.26.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: detectron2\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QHsKVVoAcf3k",
    "outputId": "d150d835-323d-42c2-d6c5-783d4e0ce559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to /private/var/folders/8t/lqdm3bfd3qg9hh_tr8ldsdh80000gn/T/pip-req-build-fyw8dts4\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /private/var/folders/8t/lqdm3bfd3qg9hh_tr8ldsdh80000gn/T/pip-req-build-fyw8dts4\n",
      "  Resolved https://github.com/facebookresearch/detectron2.git to commit 9131ce0e5bc0c89904541bc0355d933ccd6acbfb\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=7.1 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (11.0.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (3.9.2)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (2.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (2.5.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (0.1.8)\n",
      "Requirement already satisfied: tabulate in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (0.9.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (3.1.0)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (4.67.0)\n",
      "Requirement already satisfied: tensorboard in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (2.16.2)\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (0.1.9)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.1 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (2.3.0)\n",
      "Requirement already satisfied: hydra-core>=1.1 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (1.3.2)\n",
      "Requirement already satisfied: black in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (24.10.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from detectron2==0.6) (24.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
      "Requirement already satisfied: portalocker in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from matplotlib->detectron2==0.6) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from matplotlib->detectron2==0.6) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from matplotlib->detectron2==0.6) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from matplotlib->detectron2==0.6) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from matplotlib->detectron2==0.6) (6.4.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from black->detectron2==0.6) (8.1.7)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from black->detectron2==0.6) (1.0.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from black->detectron2==0.6) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from black->detectron2==0.6) (4.3.6)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from black->detectron2==0.6) (2.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from black->detectron2==0.6) (4.12.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (1.67.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (3.7)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (4.25.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from tensorboard->detectron2==0.6) (3.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->detectron2==0.6) (3.20.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/envs/new_gpu_env/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'detectron2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython -m pip install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgit+https://github.com/facebookresearch/detectron2.git\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetectron2:\u001b[39m\u001b[38;5;124m\"\u001b[39m, detectron2\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detectron2'"
     ]
    }
   ],
   "source": [
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "\n",
    "from IPython import display\n",
    "import detectron2\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BY9KJHd1WER"
   },
   "source": [
    "\n",
    "\n",
    "**INSTALLING SUPERVISION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bx_iBer09rD",
    "outputId": "45eca410-cb2f-4697-ed2b-7591292ce2f8"
   },
   "outputs": [],
   "source": [
    "!pip install supervision\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import supervision as sv\n",
    "print(\"supervision\", sv.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2gAtbBwx6xt"
   },
   "source": [
    "**DOWNLOADING THE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nV2BRTW-5AoJ"
   },
   "outputs": [],
   "source": [
    "!pip install supervision[assets] -q\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vrQX8Wz55AoK"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'supervision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msupervision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_assets, VideoAssets\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[1;32m      5\u001b[0m download_assets(VideoAssets\u001b[38;5;241m.\u001b[39mMARKET_SQUARE)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'supervision'"
     ]
    }
   ],
   "source": [
    "from supervision.assets import download_assets, VideoAssets\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "download_assets(VideoAssets.MARKET_SQUARE)\n",
    "download_assets(VideoAssets.GROCERY_STORE)\n",
    "download_assets(VideoAssets.SUBWAY)\n",
    "\n",
    "\n",
    "display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0EL4o_eOQmej",
    "outputId": "3fa8bec2-af75-4c5d-fa59-b2b656f07405"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5x6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9u4Bp6QAQsIN",
    "outputId": "92ecd7ef-e565-4060-9713-4fc8ac456d31"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'supervision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msupervision\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msv\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# extract video frame\u001b[39;00m\n\u001b[1;32m      4\u001b[0m generator \u001b[38;5;241m=\u001b[39m sv\u001b[38;5;241m.\u001b[39mget_video_frames_generator(VideoAssets\u001b[38;5;241m.\u001b[39mMARKET_SQUARE\u001b[38;5;241m.\u001b[39mvalue)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'supervision'"
     ]
    }
   ],
   "source": [
    "import supervision as sv\n",
    "\n",
    "# extract video frame\n",
    "generator = sv.get_video_frames_generator(VideoAssets.MARKET_SQUARE.value)\n",
    "iterator = iter(generator)\n",
    "frame = next(iterator)\n",
    "\n",
    "# detect\n",
    "results = model(frame, size=1280)\n",
    "detections = sv.Detections.from_yolov5(results)\n",
    "\n",
    "# annotate\n",
    "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
    "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
    "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
    "frame = label_annotator.annotate(scene=frame, detections=detections)\n",
    "\n",
    "%matplotlib inline\n",
    "sv.plot_image(frame, (16, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfmxpZgbRo91"
   },
   "source": [
    "**NOTE:** Once again, we have a lot of excess detections that we are not interested in. Let us remove all those not belonging to the person class. At the same time (to show off), we can reject all detections not exceeding `0.5` confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4SYSJEES1SX"
   },
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "\n",
    "# extract video frame\n",
    "generator = sv.get_video_frames_generator(VideoAssets.MARKET_SQUARE.value)\n",
    "iterator = iter(generator)\n",
    "frame = next(iterator)\n",
    "\n",
    "# detect\n",
    "results = model(frame, size=1280)\n",
    "detections = sv.Detections.from_yolov5(results)\n",
    "detections = detections[(detections.class_id == 0) & (detections.confidence > 0.5)]\n",
    "\n",
    "# annotate\n",
    "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
    "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
    "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
    "frame = label_annotator.annotate(scene=frame, detections=detections)\n",
    "\n",
    "%matplotlib inline\n",
    "sv.plot_image(frame, (16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhjsYhHWUTBe"
   },
   "outputs": [],
   "source": [
    "len(detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqBjWCu6UXYI"
   },
   "source": [
    "**NOTE:** We can use `Detection` API to easly calculate how many people we see on the frame. But what if we would like to divide the Market Square into smaller zones and know how many people we see each zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ul_e75nuaVZj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "# initiate polygon zone\n",
    "polygon = np.array([\n",
    "    [0, 0],\n",
    "    [1080 - 5, 0],\n",
    "    [1080 - 5, 1300 - 5],\n",
    "    [0, 1300 - 5]\n",
    "])\n",
    "video_info = sv.VideoInfo.from_video_path(VideoAssets.MARKET_SQUARE.value)\n",
    "zone = sv.PolygonZone(polygon=polygon)\n",
    "\n",
    "# extract video frame\n",
    "generator = sv.get_video_frames_generator(VideoAssets.MARKET_SQUARE.value)\n",
    "iterator = iter(generator)\n",
    "frame = next(iterator)\n",
    "\n",
    "# detect\n",
    "results = model(frame, size=1280)\n",
    "detections = sv.Detections.from_yolov5(results)\n",
    "mask = zone.trigger(detections=detections)\n",
    "detections = detections[(detections.class_id == 0) & (detections.confidence > 0.5) & mask]\n",
    "\n",
    "# annotate\n",
    "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
    "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
    "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
    "frame = label_annotator.annotate(scene=frame, detections=detections)\n",
    "frame = sv.draw_polygon(scene=frame, polygon=polygon, color=sv.Color.ROBOFLOW, thickness=6)\n",
    "\n",
    "%matplotlib inline\n",
    "sv.plot_image(frame, (16, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iv0bFpvMbMK6"
   },
   "source": [
    "**NOTE:** Importantly, zones can have a much more complex geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xz32GaDdcx5c"
   },
   "outputs": [],
   "source": [
    "sv.VideoInfo.from_video_path(VideoAssets.MARKET_SQUARE.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "k8FlU4jYet9E",
    "outputId": "f0ac194a-fc7f-41bc-8ae0-0397802fd3b8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "# initiate polygon zone\n",
    "polygon = np.array([\n",
    "    [540,  985],\n",
    "    [1620, 985],\n",
    "    [2160, 1920],\n",
    "    [1620, 2855],\n",
    "    [540,  2855],\n",
    "    [0,    1920]\n",
    "])\n",
    "video_info = sv.VideoInfo.from_video_path(VideoAssets.MARKET_SQUARE.value)\n",
    "zone = sv.PolygonZone(polygon=polygon)\n",
    "\n",
    "# extract video frame\n",
    "generator = sv.get_video_frames_generator(VideoAssets.MARKET_SQUARE.value)\n",
    "iterator = iter(generator)\n",
    "frame = next(iterator)\n",
    "\n",
    "# detect\n",
    "results = model(frame, size=1280)\n",
    "detections = sv.Detections.from_yolov5(results)\n",
    "mask = zone.trigger(detections=detections)\n",
    "detections = detections[(detections.class_id == 0) & (detections.confidence > 0.5) & mask]\n",
    "\n",
    "# annotate\n",
    "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
    "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
    "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
    "frame = label_annotator.annotate(scene=frame, detections=detections)\n",
    "frame = sv.draw_polygon(scene=frame, polygon=polygon, color=sv.Color.ROBOFLOW, thickness=6)\n",
    "\n",
    "%matplotlib inline\n",
    "sv.plot_image(frame, (16, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_kq3Uub1hfG"
   },
   "source": [
    "**NOTE:** We can also have more complex behaviours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gDvLOtzMf-o1",
    "outputId": "89b45558-d346-4b55-8c72-25cd47eafdd8"
   },
   "outputs": [],
   "source": [
    "colors = sv.ColorPalette.DEFAULT\n",
    "polygons = [\n",
    "    np.array([\n",
    "        [0, 0],\n",
    "        [1080 - 5, 0],\n",
    "        [1080 - 5, 1300 - 5],\n",
    "        [0, 1300 - 5]\n",
    "    ], np.int32),\n",
    "    np.array([\n",
    "        [1080 + 5, 0],\n",
    "        [2160, 0],\n",
    "        [2160, 1300 - 5],\n",
    "        [1080 + 5, 1300 - 5]\n",
    "    ], np.int32),\n",
    "    np.array([\n",
    "        [0, 1300 + 5],\n",
    "        [1080 - 5, 1300 + 5],\n",
    "        [1080 - 5, 3840],\n",
    "        [0, 3840]\n",
    "    ], np.int32),\n",
    "    np.array([\n",
    "        [1080 + 5, 1300 + 5],\n",
    "        [2160, 1300 + 5],\n",
    "        [2160, 3840],\n",
    "        [1080 + 5, 3840]\n",
    "    ], np.int32)\n",
    "]\n",
    "video_info = sv.VideoInfo.from_video_path(VideoAssets.MARKET_SQUARE.value)\n",
    "\n",
    "zones = [sv.PolygonZone(polygon=polygon) for polygon in polygons]\n",
    "zone_annotators = [\n",
    "    sv.PolygonZoneAnnotator(\n",
    "        zone=zone,\n",
    "        color=colors.by_idx(index),\n",
    "        thickness=4,\n",
    "        text_thickness=8,\n",
    "        text_scale=4\n",
    "    )\n",
    "    for index, zone\n",
    "    in enumerate(zones)\n",
    "]\n",
    "box_annotators = [\n",
    "    sv.BoundingBoxAnnotator(\n",
    "        color=colors.by_idx(index),\n",
    "        thickness=4,\n",
    "    )\n",
    "    for index\n",
    "    in range(len(polygons))\n",
    "]\n",
    "\n",
    "# extract video frame\n",
    "generator = sv.get_video_frames_generator(VideoAssets.MARKET_SQUARE.value)\n",
    "iterator = iter(generator)\n",
    "frame = next(iterator)\n",
    "\n",
    "# detect\n",
    "results = model(frame, size=1280)\n",
    "detections = sv.Detections.from_yolov5(results)\n",
    "detections = detections[(detections.class_id == 0) & (detections.confidence > 0.5)]\n",
    "\n",
    "for zone, zone_annotator, box_annotator in zip(zones, zone_annotators, box_annotators):\n",
    "    mask = zone.trigger(detections=detections)\n",
    "    detections_filtered = detections[mask]\n",
    "    frame = box_annotator.annotate(scene=frame, detections=detections_filtered)\n",
    "    frame = zone_annotator.annotate(scene=frame)\n",
    "\n",
    "%matplotlib inline\n",
    "sv.plot_image(frame, (16, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03f-lTPJ1uHf"
   },
   "source": [
    "**NOTE:** Or we can go completely crazy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8qahsKWtUI2"
   },
   "outputs": [],
   "source": [
    "colors = sv.ColorPalette.DEFAULT\n",
    "polygons = [\n",
    "    np.array([\n",
    "        [540,  985 ],\n",
    "        [1620, 985 ],\n",
    "        [2160, 1920],\n",
    "        [1620, 2855],\n",
    "        [540,  2855],\n",
    "        [0,    1920]\n",
    "    ], np.int32),\n",
    "    np.array([\n",
    "        [0,    1920],\n",
    "        [540,  985 ],\n",
    "        [0,    0   ]\n",
    "    ], np.int32),\n",
    "    np.array([\n",
    "        [1620, 985 ],\n",
    "        [2160, 1920],\n",
    "        [2160,    0]\n",
    "    ], np.int32),\n",
    "    np.array([\n",
    "        [540,  985 ],\n",
    "        [0,    0   ],\n",
    "        [2160, 0   ],\n",
    "        [1620, 985 ]\n",
    "    ], np.int32),\n",
    "    np.array([\n",
    "        [0,    1920],\n",
    "        [0,    3840],\n",
    "        [540,  2855]\n",
    "    ], np.int32),\n",
    "    np.array([\n",
    "        [2160, 1920],\n",
    "        [1620, 2855],\n",
    "        [2160, 3840]\n",
    "    ], np.int32),\n",
    "    np.array([\n",
    "        [1620, 2855],\n",
    "        [540,  2855],\n",
    "        [0,    3840],\n",
    "        [2160, 3840]\n",
    "    ], np.int32)\n",
    "]\n",
    "video_info = sv.VideoInfo.from_video_path(VideoAssets.MARKET_SQUARE.value)\n",
    "\n",
    "zones = [sv.PolygonZone(polygon=polygon) for polygon in polygons]\n",
    "zone_annotators = [\n",
    "    sv.PolygonZoneAnnotator(\n",
    "        zone=zone,\n",
    "        color=colors.by_idx(index),\n",
    "        thickness=6,\n",
    "        text_thickness=8,\n",
    "        text_scale=4\n",
    "    )\n",
    "    for index, zone\n",
    "    in enumerate(zones)\n",
    "]\n",
    "box_annotators = [\n",
    "    sv.BoundingBoxAnnotator(\n",
    "        color=colors.by_idx(index),\n",
    "        thickness=4,\n",
    "    )\n",
    "    for index\n",
    "    in range(len(polygons))\n",
    "]\n",
    "\n",
    "# extract video frame\n",
    "generator = sv.get_video_frames_generator(VideoAssets.MARKET_SQUARE.value)\n",
    "iterator = iter(generator)\n",
    "frame = next(iterator)\n",
    "\n",
    "# detect\n",
    "results = model(frame, size=1280)\n",
    "detections = sv.Detections.from_yolov5(results)\n",
    "detections = detections[(detections.class_id == 0) & (detections.confidence > 0.5)]\n",
    "\n",
    "for zone, zone_annotator, box_annotator in zip(zones, zone_annotators, box_annotators):\n",
    "    mask = zone.trigger(detections=detections)\n",
    "    detections_filtered = detections[mask]\n",
    "    frame = box_annotator.annotate(scene=frame, detections=detections_filtered)\n",
    "    frame = zone_annotator.annotate(scene=frame)\n",
    "\n",
    "%matplotlib inline\n",
    "sv.plot_image(frame, (16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8OaHI96zyIkt",
    "outputId": "7cae42e0-8be8-4795-8c77-ce0911545c3b"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "video_path = \"/Users/ezhil/Downloads/input.mp4\"\n",
    "video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Load YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5x6')\n",
    "\n",
    "frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "grid_width = frame_width // 2\n",
    "grid_height = frame_height // 2\n",
    "\n",
    "# Define grid polygons for zones\n",
    "polygons = [\n",
    "    np.array([[0, 0], [grid_width, 0], [grid_width, grid_height], [0, grid_height]], np.int32),      # Top-left\n",
    "    np.array([[grid_width, 0], [frame_width, 0], [frame_width, grid_height], [grid_width, grid_height]], np.int32),  # Top-right\n",
    "    np.array([[0, grid_height], [grid_width, grid_height], [grid_width, frame_height], [0, frame_height]], np.int32), # Bottom-left\n",
    "    np.array([[grid_width, grid_height], [frame_width, grid_height], [frame_width, frame_height], [grid_width, frame_height]], np.int32)  # Bottom-right\n",
    "]\n",
    "\n",
    "# Initialize zones and annotators\n",
    "colors = sv.ColorPalette.DEFAULT\n",
    "zones = [sv.PolygonZone(polygon=polygon) for polygon in polygons]\n",
    "zone_annotators = [\n",
    "    sv.PolygonZoneAnnotator(\n",
    "        zone=zone,\n",
    "        color=colors.by_idx(index),\n",
    "        thickness=3,\n",
    "        text_thickness=4,\n",
    "        text_scale=1.5\n",
    "    ) for index, zone in enumerate(zones)\n",
    "]\n",
    "box_annotators = [\n",
    "    sv.BoxAnnotator(\n",
    "        color=colors.by_idx(index),\n",
    "        thickness=2\n",
    "    ) for index in range(len(polygons))\n",
    "]\n",
    "\n",
    "# Function to process each frame\n",
    "def process_frame(frame: np.ndarray) -> np.ndarray:\n",
    "    results = model(frame, size=1280)\n",
    "    detections = sv.Detections.from_yolov5(results)\n",
    "    detections = detections[(detections.class_id == 0) & (detections.confidence > 0.5)]\n",
    "\n",
    "    for zone, zone_annotator, box_annotator in zip(zones, zone_annotators, box_annotators):\n",
    "        mask = zone.trigger(detections=detections)\n",
    "        detections_filtered = detections[mask]\n",
    "        frame = box_annotator.annotate(scene=frame, detections=detections_filtered)\n",
    "        frame = zone_annotator.annotate(scene=frame)\n",
    "    return frame\n",
    "\n",
    "# Display loop\n",
    "while video_capture.isOpened():\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    annotated_frame = process_frame(frame)\n",
    "    \n",
    "    # Display frame using OpenCV\n",
    "    cv2.imshow(\"Annotated Video\", annotated_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
